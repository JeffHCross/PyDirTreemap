{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = 'D:\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dask.utils import format_bytes\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e7TeCo2QKrP"
   },
   "outputs": [],
   "source": [
    "def gen_file_row(f):\n",
    "  return {'path':str(f),'filename':f.name,'directory':str(f.parent),'type':f.suffix,'bytes':f.stat().st_size}, f.stat().st_size\n",
    "\n",
    "def process_dir(d):\n",
    "  paths = []\n",
    "  dir_size = 0\n",
    "  try:\n",
    "    for p in d.iterdir():\n",
    "      try:\n",
    "        if p.is_dir():\n",
    "          res, b = process_dir(p)\n",
    "          paths = paths + res\n",
    "          dir_size += b\n",
    "        elif p.is_file():\n",
    "          res, b = gen_file_row(p)\n",
    "          paths.append(res)\n",
    "          dir_size += b\n",
    "      except (FileNotFoundError, PermissionError):\n",
    "        continue\n",
    "  except (FileNotFoundError, PermissionError):\n",
    "    paths.append({'path':str(d),\n",
    "                  'filename':d.name if d.name != '' else str(d),\n",
    "                  'directory':str(d.parent) if d.parent != d else \"\",\n",
    "                  'type':'directory',\n",
    "                  'bytes':0})\n",
    "    return paths, 0\n",
    "  paths.append({'path':str(d),\n",
    "                'filename':d.name if d.name != '' else str(d),\n",
    "                'directory':str(d.parent) if d.parent != d else \"\",\n",
    "                'type':'directory',\n",
    "                'bytes':dir_size})\n",
    "  return paths, dir_size\n",
    "\n",
    "def process_with_Pool(d):\n",
    "  pool = Pool()\n",
    "  glob_list = list(d.glob(\"**/*\"))\n",
    "  dir_list  = [{'path':x.name,'directory':str(x.parent),'type':'directory','bytes':0} for x in glob_list if x.is_dir()]\n",
    "  print(dir_list[0:5])\n",
    "  file_list = [x for x in glob_list if not x.is_dir()]\n",
    "  res = pool.map(gen_file_row, file_list)\n",
    "  return dir_list + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "KekjpZuid3OA",
    "outputId": "7a13c84d-8d26-471f-d8fe-ea08f352344d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#data=process_dir_Pool(Path(root_directory))\n",
    "data, __ =process_dir(Path(root_directory))\n",
    "df = pd.DataFrame(data)\n",
    "df['filesize'] = df['bytes'].apply(lambda x: format_bytes(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "  largest_dir = df.loc[(df['type'] == 'directory') & (df['path'] != root_directory)].sort_values(by=['bytes','directory'],ascending=[False,True]).head(10).reset_index()\n",
    "  largest_dir.index = range(1,11)\n",
    "  print(\"10 largest directories\")\n",
    "  display(largest_dir[['path','directory','filesize']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "  print(\"10 largest files\")\n",
    "  largest_files = df.loc[df['type'] != 'directory'].nlargest(10,'bytes').reset_index(drop=True)\n",
    "  largest_files.index = range(1,11)\n",
    "  display(largest_files[['filename','directory','type','filesize']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "odajmRGSi0en",
    "outputId": "337d0bfa-d633-4247-a6b6-5171370f5a74"
   },
   "outputs": [],
   "source": [
    "fig = px.treemap(df.nlargest(100,'bytes').sort_values(by='directory'),\n",
    "        branchvalues = \"total\",\n",
    "        names = 'filename',\n",
    "        ids = 'path',\n",
    "        parents = 'directory',\n",
    "        values = 'bytes',\n",
    "        title = '100 largest directories/files',\n",
    "        hover_data = {'filename':True,'path':False,'bytes':False,'filesize':True,'directory':True,'type':True},\n",
    "        color = 'type'\n",
    ")\n",
    "#fig.update_traces(root_color=\"lightgrey\")\n",
    "fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2l/Pq6BCGJGKbQkQmyJVY",
   "collapsed_sections": [],
   "name": "PyDirTreeMap.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "5871f9ceaeb58903a062280df9e35c51c3f2838963fa6a6e83036660d9d47fa0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
